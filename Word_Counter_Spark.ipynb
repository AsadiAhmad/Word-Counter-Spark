{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Word-count in Apache Spark"
      ],
      "metadata": {
        "id": "HlQPIWm41JHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 - Install dependencies :"
      ],
      "metadata": {
        "id": "rT4S7diO1fRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGtVcHhq1xRE",
        "outputId": "f7b43028-9090-430b-9eb3-8990fd3e7a42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=d29d78562d389b46bef785ba40510abb0dc92dec623e842e0555a33bc6d1936e\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 - Create source :"
      ],
      "metadata": {
        "id": "w0q0lOPL2HbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "sc = pyspark.SparkContext('local[*]')"
      ],
      "metadata": {
        "id": "75zkZ8Qp2GOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 - Here is our Doc :"
      ],
      "metadata": {
        "id": "nXw8zf_x1Nu0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0xyG9VHrrWB"
      },
      "outputs": [],
      "source": [
        "Doc = \"to be or not to be\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4 - Split to Words :"
      ],
      "metadata": {
        "id": "krJcXQ9r1WFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = Doc.split()\n",
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5Iif8z_1cb7",
        "outputId": "27c57b0c-bc4a-4ae2-cab1-bcfc89d3241d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to', 'be', 'or', 'not', 'to', 'be']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5 - Transfering Words into Spark DataFrame (RDD) :"
      ],
      "metadata": {
        "id": "aPFD8S5y2XzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words_rdd = sc.parallelize(words)\n",
        "words_rdd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxhQ5umg29F0",
        "outputId": "4d4c6889-2684-4df4-9a6e-0bf765eb1edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:289"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6 - Mapping RDD :"
      ],
      "metadata": {
        "id": "chBXxQ0a3EW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_tuples_rdd = words_rdd.map(lambda x: (x, 1))\n",
        "word_tuples_rdd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYvGkUzE3IWU",
        "outputId": "90a3aed8-6a4c-4239-fd57-c36969ff8967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonRDD[1] at RDD at PythonRDD.scala:53"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7 - Collecting RDD :"
      ],
      "metadata": {
        "id": "ZsH9shEV3bkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_tuples_rdd.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeOuil6l3eV2",
        "outputId": "b63bb5cc-7ae9-4f16-b345-4cbd55253535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('to', 1), ('be', 1), ('or', 1), ('not', 1), ('to', 1), ('be', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8 - Reducing RDD :"
      ],
      "metadata": {
        "id": "7lTm-ZmF6Ixt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_counts_rdd = word_tuples_rdd.reduceByKey(lambda x, y: x + y)\n",
        "word_counts_rdd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naC-0m2n6Hv9",
        "outputId": "157749ab-2bf1-4914-9709-1deb0387349e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonRDD[6] at RDD at PythonRDD.scala:53"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9 - Collecting RDD :"
      ],
      "metadata": {
        "id": "cojI2uah7SO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_counts = word_counts_rdd.collect()\n",
        "word_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLyPFwHb7GB0",
        "outputId": "0218c9bd-1282-44c5-d76e-b3d78fd3d616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('to', 2), ('be', 2), ('or', 1), ('not', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# All Things in 4 line:"
      ],
      "metadata": {
        "id": "5BrB7uqU73eP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"to be or not to be\".split()\n",
        "rdd = sc.parallelize(text)\n",
        "counts = rdd.map(lambda word: (word, 1)).reduceByKey(lambda x, y: x + y)\n",
        "counts.collect()"
      ],
      "metadata": {
        "id": "ksccEOAJ78C-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05571d1c-8ff2-41f3-a5b4-423bd923edf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('to', 2), ('be', 2), ('or', 1), ('not', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}